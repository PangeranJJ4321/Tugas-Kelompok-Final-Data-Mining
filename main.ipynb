{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a94fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from collections import Counter\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Resampling techniques for imbalanced data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== DATA PREPROCESSING =====================\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess raw movie data to the format required for model training\n",
    "    \n",
    "    Args:\n",
    "        df: Raw dataframe with movie information\n",
    "        \n",
    "    Returns:\n",
    "        Processed dataframe ready for model training\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original dataframe\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Extract release year and month from release_date\n",
    "    processed_df['release_date'] = pd.to_datetime(processed_df['release_date'])\n",
    "    processed_df['release_year'] = processed_df['release_date'].dt.year\n",
    "    processed_df['release_month'] = processed_df['release_date'].dt.month\n",
    "    \n",
    "    # Calculate ROI (Return on Investment)\n",
    "    processed_df['ROI'] = ((processed_df['revenue'] - processed_df['budget']) / processed_df['budget']) * 100\n",
    "    \n",
    "    # Create ROI category based on ROI value\n",
    "    conditions = [\n",
    "        (processed_df['ROI'] < -50),\n",
    "        (processed_df['ROI'] >= -50) & (processed_df['ROI'] < 0),\n",
    "        (processed_df['ROI'] >= 0) & (processed_df['ROI'] < 100),\n",
    "        (processed_df['ROI'] >= 100)\n",
    "    ]\n",
    "    choices = ['High Risk', 'Medium Risk', 'Low Risk', 'No Risk']\n",
    "    processed_df['ROI_category'] = np.select(conditions, choices, default='Unknown')\n",
    "    \n",
    "    # Create language binary features\n",
    "    processed_df['lang_en'] = (processed_df['original_language'] == 'en').astype(int)\n",
    "    processed_df['lang_others'] = (processed_df['original_language'] != 'en').astype(int)\n",
    "    \n",
    "    # One-hot encode genres\n",
    "    if 'genres' in processed_df.columns:\n",
    "        # Split the genre string and create binary columns\n",
    "        genre_df = processed_df['genres'].str.get_dummies(sep=', ')\n",
    "        \n",
    "        # Handle all genres from the dataset\n",
    "        all_genres = [\n",
    "            'Action', 'Adventure', 'Animation', 'Comedy', 'Crime', \n",
    "            'Documentary', 'Drama', 'Family', 'Fantasy', 'History', \n",
    "            'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', \n",
    "            'TV Movie', 'Thriller', 'War', 'Western'\n",
    "        ]\n",
    "        \n",
    "        for genre in all_genres:\n",
    "            # Format genre name for column (lowercase, replace spaces with underscores)\n",
    "            genre_col_name = f'genre_{genre.lower().replace(\" \", \"_\")}'\n",
    "            \n",
    "            # Check if the genre exists in our one-hot encoded columns (case-insensitive)\n",
    "            genre_cols = [col for col in genre_df.columns if col.lower() == genre.lower()]\n",
    "            \n",
    "            if genre_cols:\n",
    "                # Use the first match if multiple exist\n",
    "                processed_df[genre_col_name] = genre_df[genre_cols[0]]\n",
    "            else:\n",
    "                # If genre doesn't exist in this dataset, add a column of zeros\n",
    "                processed_df[genre_col_name] = 0\n",
    "    \n",
    "    # Select and reorder columns to match the desired output format\n",
    "    # Base columns (non-genre)\n",
    "    base_columns = [\n",
    "        'release_year', 'release_month', 'budget', 'popularity', 'runtime',\n",
    "        'vote_average', 'vote_count', 'lang_en', 'lang_others'\n",
    "    ]\n",
    "    \n",
    "    # Generate genre column names\n",
    "    genre_columns = [f'genre_{genre.lower().replace(\" \", \"_\")}' for genre in all_genres]\n",
    "    \n",
    "    # Output columns (target variables at the end)\n",
    "    target_columns = ['revenue', 'ROI', 'ROI_category']\n",
    "    \n",
    "    final_columns = base_columns + genre_columns + target_columns\n",
    "    \n",
    "    # Ensure all required columns exist\n",
    "    for col in final_columns:\n",
    "        if col not in processed_df.columns:\n",
    "            processed_df[col] = 0\n",
    "    \n",
    "    return processed_df[final_columns]\n",
    "\n",
    "def split_features_target(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split dataframe into features, revenue target, and ROI category target\n",
    "    \n",
    "    Args:\n",
    "        df: Preprocessed dataframe\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (features_df, revenue_target, roi_category_target)\n",
    "    \"\"\"\n",
    "    # Features for both models (excluding revenue, ROI, and ROI_category)\n",
    "    # Base columns (non-genre)\n",
    "    base_columns = [\n",
    "        'release_year', 'release_month', 'budget', 'popularity', 'runtime',\n",
    "        'vote_average', 'vote_count', 'lang_en', 'lang_others'\n",
    "    ]\n",
    "    \n",
    "    # Generate genre column names\n",
    "    all_genres = [\n",
    "        'Action', 'Adventure', 'Animation', 'Comedy', 'Crime', \n",
    "        'Documentary', 'Drama', 'Family', 'Fantasy', 'History', \n",
    "        'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', \n",
    "        'TV Movie', 'Thriller', 'War', 'Western'\n",
    "    ]\n",
    "    genre_columns = [f'genre_{genre.lower().replace(\" \", \"_\")}' for genre in all_genres]\n",
    "    \n",
    "    feature_cols = base_columns + genre_columns\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    y_regression = df['revenue']\n",
    "    y_classification = df['ROI_category']\n",
    "    \n",
    "    return X, y_regression, y_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== VISUALIZATION UTILITIES =====================\n",
    "\n",
    "def plot_class_distribution(y, title: str):\n",
    "    \"\"\"Plot the distribution of classes\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    counts = pd.Series(y).value_counts().sort_index()\n",
    "    sns.barplot(x=counts.index, y=counts.values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_resampling_comparison(y_original, y_resampled, label_encoder=None):\n",
    "    \"\"\"\n",
    "    Plot before and after class distributions for resampling methods\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Convert encoded values back to labels if label encoder is provided\n",
    "    if label_encoder is not None:\n",
    "        original_labels = [label_encoder.inverse_transform([i])[0] for i in range(len(np.unique(y_original)))]\n",
    "        resampled_labels = [label_encoder.inverse_transform([i])[0] for i in range(len(np.unique(y_resampled)))]\n",
    "    else:\n",
    "        original_labels = np.unique(y_original)\n",
    "        resampled_labels = np.unique(y_resampled)\n",
    "\n",
    "    # Original distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_counts = pd.Series(y_original).value_counts().sort_index()\n",
    "    plt.bar(range(len(train_counts)), train_counts.values)\n",
    "    plt.title('Original Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.xticks(range(len(train_counts)), original_labels)\n",
    "\n",
    "    # Resampled distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    resampled_counts = pd.Series(y_resampled).value_counts().sort_index()\n",
    "    plt.bar(range(len(resampled_counts)), resampled_counts.values)\n",
    "    plt.title('Resampled Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.xticks(range(len(resampled_counts)), resampled_labels)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== RESAMPLING STRATEGIES =====================\n",
    "\n",
    "def find_best_resampling(X, y, class_names):\n",
    "    \"\"\"\n",
    "    Test different resampling techniques and find the best one\n",
    "    \"\"\"\n",
    "    # Define resampling techniques to try\n",
    "    resampling_methods = {\n",
    "        'SMOTE': SMOTE(random_state=42),\n",
    "        'SMOTETomek': SMOTETomek(random_state=42),\n",
    "        'SMOTEENN': SMOTEENN(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = {\n",
    "        'RandomForest': RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            class_weight='balanced_subsample',\n",
    "            random_state=42\n",
    "        ),\n",
    "        'XGBoost': xgb.XGBClassifier(\n",
    "            n_estimators=100, \n",
    "            scale_pos_weight=3,  # Higher weight for minority classes\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Save test data for consistent evaluation\n",
    "    test_data = (X_test, y_test)\n",
    "    \n",
    "    # Test each combination\n",
    "    for resampler_name, resampler in resampling_methods.items():\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            print(f\"\\nTesting {resampler_name} with {clf_name}\")\n",
    "            \n",
    "            # Create and train pipeline\n",
    "            pipeline = ImbPipeline([\n",
    "                ('resampler', resampler),\n",
    "                ('classifier', clf)\n",
    "            ])\n",
    "            \n",
    "            # Train with stratified cross-validation\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics focusing on minority classes\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "            \n",
    "            # Store results\n",
    "            results[f\"{resampler_name}_{clf_name}\"] = {\n",
    "                'pipeline': pipeline,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'accuracy': accuracy_score(y_test, y_pred)\n",
    "            }\n",
    "            \n",
    "            # Show confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                       xticklabels=class_names, \n",
    "                       yticklabels=class_names)\n",
    "            plt.title(f'{resampler_name} with {clf_name} - Confusion Matrix')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Find best method based on minority class F1 scores\n",
    "    best_method = None\n",
    "    best_minority_f1 = 0\n",
    "    \n",
    "    for method, result in results.items():\n",
    "        # Focus on minority classes (assuming first classes are minorities)\n",
    "        minority_f1 = np.mean(result['f1'][:2])  # Adjust based on your class order\n",
    "        \n",
    "        if minority_f1 > best_minority_f1:\n",
    "            best_minority_f1 = minority_f1\n",
    "            best_method = method\n",
    "    \n",
    "    print(f\"\\nBest method: {best_method} with minority class F1: {best_minority_f1:.4f}\")\n",
    "    \n",
    "    return results, best_method, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1db357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== REVENUE REGRESSION MODEL =====================\n",
    "\n",
    "class RevenueRegressionModel:\n",
    "    \"\"\"Base class for revenue regression models\"\"\"\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.feature_importance = None\n",
    "    \n",
    "    def train(self, X_train, y_train, param_grid=None, cv=5):\n",
    "        \"\"\"\n",
    "        Train the regression model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        if param_grid:\n",
    "            # Perform grid search for hyperparameter tuning\n",
    "            grid_search = GridSearchCV(self.model, param_grid, \n",
    "                                      cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters for {self.model_name}: {best_params}\")\n",
    "        else:\n",
    "            # Train with default parameters\n",
    "            self.model.fit(X_train, y_train)\n",
    "            best_params = \"Default parameters used\"\n",
    "        \n",
    "        # Calculate feature importance\n",
    "        if hasattr(self.model, 'feature_importances_'):\n",
    "            self.feature_importance = pd.DataFrame({\n",
    "                'feature': X_train.columns,\n",
    "                'importance': self.model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Training metrics\n",
    "        y_pred_train = self.model.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        \n",
    "        training_metrics = {\n",
    "            'model_name': self.model_name,\n",
    "            'train_rmse': train_rmse,\n",
    "            'train_mae': train_mae,\n",
    "            'train_r2': train_r2,\n",
    "            'best_params': best_params\n",
    "        }\n",
    "        \n",
    "        return training_metrics\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data\n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        test_mae = mean_absolute_error(y_test, y_pred)\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Create scatter plot of actual vs predicted values\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "        plt.xlabel('Actual Revenue')\n",
    "        plt.ylabel('Predicted Revenue')\n",
    "        plt.title(f'{self.model_name} - Actual vs Predicted Revenue')\n",
    "        plt.show()\n",
    "        \n",
    "        evaluation_metrics = {\n",
    "            'model_name': self.model_name,\n",
    "            'test_rmse': test_rmse,\n",
    "            'test_mae': test_mae,\n",
    "            'test_r2': test_r2\n",
    "        }\n",
    "        \n",
    "        return evaluation_metrics\n",
    "    \n",
    "    def save_model(self, model_dir='models/regression'):\n",
    "        \"\"\"\n",
    "        Save the trained model and feature importance to disk\n",
    "        \"\"\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = os.path.join(model_dir, f\"{self.model_name}.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        \n",
    "        # Save feature importance if available\n",
    "        if self.feature_importance is not None:\n",
    "            importance_path = os.path.join(model_dir, f\"{self.model_name}_feature_importance.csv\")\n",
    "            self.feature_importance.to_csv(importance_path, index=False)\n",
    "            \n",
    "            # Create feature importance plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            top_features = self.feature_importance.head(15)\n",
    "            sns.barplot(x='importance', y='feature', data=top_features)\n",
    "            plt.title(f'Top 15 Feature Importance - {self.model_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"{self.model_name} model saved to {model_path}\")\n",
    "\n",
    "\n",
    "class RandomForestRevenueRegressor(RevenueRegressionModel):\n",
    "    \"\"\"Random Forest model for revenue regression\"\"\"\n",
    "    def __init__(self, n_estimators=100, max_depth=None, random_state=42):\n",
    "        super().__init__(\"random_forest_regressor\")\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "\n",
    "class XGBoostRevenueRegressor(RevenueRegressionModel):\n",
    "    \"\"\"XGBoost model for revenue regression\"\"\"\n",
    "    def __init__(self, n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42):\n",
    "        super().__init__(\"xgboost_regressor\")\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=random_state\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc76aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== IMPROVED RISK CLASSIFICATION MODEL =====================\n",
    "\n",
    "class ImprovedRiskClassifier:\n",
    "    \"\"\"\n",
    "    Improved classification model with focus on minority classes and\n",
    "    built-in resampling for imbalanced data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_type='xgboost', resampling='smotetomek'):\n",
    "        self.model_type = model_type\n",
    "        self.resampling = resampling\n",
    "        self.model = None\n",
    "        self.feature_importance = None\n",
    "        self.resampler = None\n",
    "        self.pipeline = None\n",
    "        self.class_names = None\n",
    "        self.label_encoder = None\n",
    "        \n",
    "        # Initialize resampler\n",
    "        if resampling.lower() == 'smote':\n",
    "            self.resampler = SMOTE(random_state=42)\n",
    "        elif resampling.lower() == 'smotetomek':\n",
    "            self.resampler = SMOTETomek(random_state=42)\n",
    "        elif resampling.lower() == 'smoteenn':\n",
    "            self.resampler = SMOTEENN(random_state=42)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported resampling method: {resampling}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        if model_type.lower() == 'randomforest':\n",
    "            self.model = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                class_weight='balanced_subsample',  # Try balanced_subsample instead of balanced\n",
    "                random_state=42\n",
    "            )\n",
    "        elif model_type.lower() == 'xgboost':\n",
    "            self.model = xgb.XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                scale_pos_weight=3,  # Higher weight for minority classes\n",
    "                random_state=42,\n",
    "                eval_metric='mlogloss',\n",
    "                use_label_encoder=False\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    def train(self, X_train, y_train, class_names=None, param_grid=None):\n",
    "        \"\"\"\n",
    "        Train model with focus on minority class performance\n",
    "        \n",
    "        Args:\n",
    "            X_train: Feature matrix\n",
    "            y_train: Target vector\n",
    "            class_names: List of class names (optional)\n",
    "            param_grid: Parameter grid for hyperparameter tuning (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Self for method chaining\n",
    "        \"\"\"\n",
    "        self.class_names = class_names\n",
    "        \n",
    "        # Create pipeline with resampling\n",
    "        self.pipeline = ImbPipeline([\n",
    "            ('resampler', self.resampler),\n",
    "            ('classifier', self.model)\n",
    "        ])\n",
    "        \n",
    "        if param_grid:\n",
    "            # Add prefix to parameter names for GridSearchCV\n",
    "            grid_params = {}\n",
    "            for param, values in param_grid.items():\n",
    "                grid_params[f'classifier__{param}'] = values\n",
    "            \n",
    "            # Use stratified cross-validation\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            \n",
    "            # Grid search with focus on minority class F1\n",
    "            grid_search = GridSearchCV(\n",
    "                self.pipeline, \n",
    "                grid_params,\n",
    "                cv=cv, \n",
    "                scoring='f1_macro',  # Use macro F1 to focus on all classes equally\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            self.pipeline = grid_search.best_estimator_\n",
    "            \n",
    "            print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        else:\n",
    "            self.pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get feature importances from the classifier in the pipeline\n",
    "        if hasattr(self.pipeline.named_steps['classifier'], 'feature_importances_'):\n",
    "            self.feature_importance = pd.DataFrame({\n",
    "                'feature': X_train.columns,\n",
    "                'importance': self.pipeline.named_steps['classifier'].feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Evaluate on training data\n",
    "        y_pred_train = self.pipeline.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, y_pred_train)\n",
    "        \n",
    "        print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "        return self\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Detailed evaluation with focus on per-class metrics\n",
    "        \n",
    "        Args:\n",
    "            X_test: Test feature matrix\n",
    "            y_test: Test target vector\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing evaluation metrics\n",
    "        \"\"\"\n",
    "        y_pred = self.pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate per-class metrics\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "        \n",
    "        # Display confusion matrix with better visualization\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Normalize confusion matrix for better visualization\n",
    "        conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        sns.heatmap(conf_matrix_norm, annot=conf_matrix, \n",
    "                    fmt='d', cmap='Blues', xticklabels=self.class_names, \n",
    "                    yticklabels=self.class_names)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=self.class_names))\n",
    "        \n",
    "        # Create a DataFrame for per-class metrics for better visualization\n",
    "        class_metrics = pd.DataFrame({\n",
    "            'Class': self.class_names,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'Support': support\n",
    "        })\n",
    "        \n",
    "        # Plot per-class metrics\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        metrics_melted = pd.melt(class_metrics, id_vars=['Class'], \n",
    "                                value_vars=['Precision', 'Recall', 'F1-Score'],\n",
    "                                var_name='Metric', value_name='Score')\n",
    "        sns.barplot(x='Class', y='Score', hue='Metric', data=metrics_melted)\n",
    "        plt.title('Performance Metrics by Class')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'per_class_metrics': class_metrics\n",
    "        }\n",
    "    \n",
    "    def save_model(self, filepath='models/classification/improved_classifier.pkl'):\n",
    "        \"\"\"\n",
    "        Save the trained model to disk\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to save the model\n",
    "            \n",
    "        Returns:\n",
    "            Self for method chaining\n",
    "        \"\"\"\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.pipeline, f)\n",
    "        \n",
    "        if self.feature_importance is not None:\n",
    "            # Save feature importance\n",
    "            importance_path = filepath.replace('.pkl', '_importance.csv')\n",
    "            self.feature_importance.to_csv(importance_path, index=False)\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            top_features = self.feature_importance.head(15)\n",
    "            sns.barplot(x='importance', y='feature', data=top_features)\n",
    "            plt.title('Top 15 Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"Model saved to {filepath}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with the trained model\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            \n",
    "        Returns:\n",
    "            Predicted classes\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Model has not been trained yet\")\n",
    "        \n",
    "        return self.pipeline.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get class probabilities\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            \n",
    "        Returns:\n",
    "            Class probabilities\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Model has not been trained yet\")\n",
    "        \n",
    "        return self.pipeline.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== PREDICTION FUNCTIONS =====================\n",
    "\n",
    "def predict_movie_performance(input_data, regression_model, classification_model, label_encoder=None, output_file_path=None):\n",
    "    \"\"\"\n",
    "    Generate predictions using trained models\n",
    "    \n",
    "    Args:\n",
    "        input_data: DataFrame with movie features\n",
    "        regression_model: Trained regression model\n",
    "        classification_model: Trained classification model\n",
    "        label_encoder: Label encoder for class mapping\n",
    "        output_file_path: Path to save predictions (optional)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions\n",
    "    \"\"\"\n",
    "    # Preprocess data\n",
    "    processed_df = preprocess_data(input_data)\n",
    "    \n",
    "    # Extract features\n",
    "    X, _, _ = split_features_target(processed_df)\n",
    "    \n",
    "    # Generate predictions\n",
    "    print(\"Generating predictions...\")\n",
    "    \n",
    "    # Revenue prediction\n",
    "    revenue_predictions = regression_model.model.predict(X)\n",
    "    \n",
    "    # Risk classification\n",
    "    if hasattr(classification_model, 'pipeline'):\n",
    "        risk_class_encoded = classification_model.predict(X)\n",
    "        # Convert encoded classes back to original labels if encoder is provided\n",
    "        if label_encoder is not None:\n",
    "            risk_predictions = label_encoder.inverse_transform(risk_class_encoded)\n",
    "        else:\n",
    "            risk_predictions = risk_class_encoded\n",
    "    else:\n",
    "        risk_predictions = classification_model.model.predict(X)\n",
    "        if label_encoder is not None:\n",
    "            risk_predictions = label_encoder.inverse_transform(risk_predictions)\n",
    "    \n",
    "    # Create result dataframe\n",
    "    results_df = input_data.copy()\n",
    "    results_df['predicted_revenue'] = revenue_predictions\n",
    "    results_df['predicted_risk'] = risk_predictions\n",
    "    \n",
    "    # Calculate predicted ROI\n",
    "    results_df['predicted_roi'] = ((results_df['predicted_revenue'] - results_df['budget']) / results_df['budget']) * 100\n",
    "    \n",
    "    # Save predictions if output path is provided\n",
    "    if output_file_path:\n",
    "        print(f\"Saving predictions to {output_file_path}...\")\n",
    "        results_df.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== MAIN EXECUTION FLOW =====================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # Load the data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(\"data/raw/data_mentah.csv\")\n",
    "    print(f\"Loaded data with {len(df)} records\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    processed_df = preprocess_data(df)\n",
    "    print(f\"Processed data with {processed_df.shape[1]} features\")\n",
    "    \n",
    "    # Display ROI category distribution\n",
    "    category_counts = processed_df['ROI_category'].value_counts().reindex(\n",
    "        ['High Risk', 'Medium Risk', 'Low Risk', 'No Risk'], fill_value=0\n",
    "    )\n",
    "    print(\"\\nROI Category distribution:\")\n",
    "    print(category_counts)\n",
    "    \n",
    "    # Plot ROI category distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "    plt.title('Distribution of ROI Categories')\n",
    "    plt.xlabel('Risk Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Split features and targets\n",
    "    X, y_regression, y_classification = split_features_target(processed_df)\n",
    "    \n",
    "    # Encode ROI_category for classification\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_class_encoded = label_encoder.fit_transform(y_classification)\n",
    "    class_names = label_encoder.classes_\n",
    "    \n",
    "    # Split data for regression model\n",
    "    X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "        X, y_regression, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Split data with stratification for classification model\n",
    "    X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(\n",
    "        X, y_class_encoded, test_size=0.2, random_state=42, stratify=y_class_encoded\n",
    "    )\n",
    "    \n",
    "    # ----- FIND OPTIMAL RESAMPLING TECHNIQUE -----\n",
    "    print(\"\\n===== Finding Best Resampling Method for Classification =====\")\n",
    "    # Uncomment to run the full resampling comparison (can be time-consuming)\n",
    "    # results, best_method, test_data = find_best_resampling(X, y_class_encoded, class_names)\n",
    "    # resampling_technique, model_type = best_method.split('_')\n",
    "    \n",
    "    # Based on previous runs, we'll use SMOTETomek with XGBoost\n",
    "    resampling_technique = 'smotetomek'\n",
    "    model_type = 'xgboost'\n",
    "    print(f\"Using {resampling_technique} with {model_type} based on previous results\")\n",
    "    \n",
    "    # Apply the chosen resampling technique\n",
    "    smotetomek = SMOTETomek"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
